---
title: "XR UX should be Edible"
date: "Jun 9, 2023"
description: "A quick take on Apple Vision Pro and why UX/design is the real differentiator in XR."
tags: [Tech]
slug: ediblexr
subtitle: "A very quick take."
---

Apple's $3500 Vision Pro was announced last Monday as part of WWDC, boasting passthrough, seamless daily use, and OLED projections as part of its offerings. In a world where VCs and grifters are seemingly past the "metaverse" hype, where there are multiples of new HMD (head-mounted display) companies popping up and dying every few years, and the high investment into XR from Meta, what is making Apple's headset distinguished?

It is not at all the technology. In fact, practically all of the tech and patents have been implemented in some fashion years before. Many individuals and Magic Leap employees have pointed out similarities with previous technical applications and attempts at features such as hand gesture tracking, spatial menus, eye tracking, and depth-based obfuscation of real-world objects, all of which Apple included in the Vision Pro and visionOS.

If companies like Magic Leap, Meta, Pico, HTC, and Microsoft have been researching and improving XR experiences for the past few years, what is missing from their work that Apple is improving upon? I can't say that Apple's gamble with XR will be a success though, the price is enough to defer the majority of individuals, non-Apple diehard fans who wouldn't shell out money for the $500 Quest 3. However, as Palmer Luckey mentioned previously, Apple is making something that people want.

In my observation, the biggest disadvantage of XR taking off was that 1) profitable use cases are limited, and 2) most devices were a pain to use. They relied on third-party devs too much.

In the VR world, Oculus Quests and VIVE HMDs were widely used. Quests are affordable and marketed to gamers, making it a nice gimmick to use to swing lightsabers at boxes with arrows on them. VIVE sets were more expensive but served as valuable assets to enterprise and research; VIVE trackers and lighthouses served as highly accurate 6 DoF object markers for robotics, XR simulations, and object identifiers. Additionally, they worked with many haptic devices, such as the HaptX sets.

The benefits of VR are the fact that you can pretty easily immerse yourself in a virtual world and orient yourself in it with proper game design, such as being able to see your end effectors, as well as proper haptics and sound design. However, cybersickness (dizzyness and fatigue from using an XR HMD for extended amounts of time) is prevalent in these headsets; enterprise users would not be able to use these headsets for extended times for training and designing, and video game players could not use these devices for hours-long game sessions as they can with monitors. Additionally, setup and development with these devices were tedious; Meta locked Oculus development behind Facebook accounts and restricted computer connection, and VIVE lighthouses can be a joy to sync with SteamVR /s.

Similar grievances came with AR. Microsoft Hololens was probably one of the more powerful lineups but came with only a 55 DoV, didn't have a strong developer community, and was mainly targeted toward enterprises and the government for limited use cases, such as wiring aids and Google Glass-like information overlays. More recently, companies like Magic Leap and Lenovo have come out with better AR glasses, but also run into many of the same issues with gesturing and UX that previous AR headsets have had. I have not worked extensively with AR and with these headsets, so I can't comment much on how well they operate.

With the Quest Pro, Vive XR Elite, and now the Vision Pro, passthrough seems to be a desirable mix, allowing digital spatial immersion in the real world without the DoV restrictions of AR. With Quest's demo though, it still felt lifeless and not very attractive from a nontechnical perspective. [Take a look at the Lynx headset though, I think its hardware form factor and optics have an edge over the typical HMD in passthrough]

Have you ever heard of the phrase, "Art/design so good that I want to eat it"?

"Yummy" design, native to visionOS and the Vision Pro is what ties together Apple's vision of bringing XR to someone who may not be a gamer, who is not a dev, and who just wants to augment their real world with some more tech seamlessly. To put it simply, the spatial design just looks good, blending a good mix of material and skeuomorphism with blurred glass backgrounds, rounded corners, and spatial design that brings the best of Swift UI to the 3D world. Take a look at Twitter and look at the work that many Apple designers are showcasing, as well as the tutorials on [spatial design](https://twitter.com/lindadong/status/1666099904245288963). There is a lot of focus on how to make virtual screens and renders actually feel like they belong, with proper depth and interactivity, rather than just weird projections in the world. With good UX and "killer apps" made by devs (which Apple is seeming to do a good job promoting), exponential user growth and interest is highly attainable.

*"It is going to be expensive, but I think that they're following a pretty smart strategy, which is to make VR into something everybody wants before it's something that everybody can afford, which was kind of our position in the early days when we started Oculus." - Palmer Luckey*

As I have been saying with other technology that have had hype cycles (blockchain, AI, edge compute), each of these has a value added to specific parts of a stack. XR's value is the ability to augment and transform your physical surrounding into something digitally improved. Boeing successfully implements AR into their manufacturing line because it improves their workflow. Airlines sometimes train pilots using VR due to the cheaper and improved immersiveness. Similar to Humane, Apple seems to be moving toward a world where our daily lives can be augmented, and we could wear HMDs for an improved experience over being constrained to our phone screens.

I can talk about the tech and how the headset compares in specs across the board, but my parents and nontechnical friends would not care about that if the Vision Pro had the UX of the Hololens 1. XR UI should be something we can touch and believe is real in our world, something we can sink our teeth into; not holograms of a screen that ghostly passes through.

@anyone who has access whenever the Vision Pro releases, I want to try it :)
